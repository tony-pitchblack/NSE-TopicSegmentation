{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as PACK, pad_packed_sequence as PAD\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from abc import ABC, abstractmethod\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brazen\\Miniconda3\\envs\\default\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# SMALL SBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "nse_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "def batch_calc_docs_embs(batch_docs):\n",
    "        list_docs_embs = []\n",
    "        for doc in batch_docs:\n",
    "            tokenized_docs = tokenizer(\n",
    "                doc,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors='pt',\n",
    "                return_token_type_ids=False,\n",
    "                return_attention_mask=False\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                tokenized_docs = {k: v.to(nse_model.device) for k, v in tokenized_docs.items()}\n",
    "                model_output = nse_model(**tokenized_docs)\n",
    "\n",
    "            docs_embs = 0\n",
    "            docs_embs = model_output.last_hidden_state[:, 0, :]\n",
    "            docs_embs = torch.nn.functional.normalize(docs_embs)\n",
    "            list_docs_embs.append(docs_embs)\n",
    "        batch_docs_embs = pad_sequence(list_docs_embs, batch_first=True)\n",
    "        return batch_docs_embs\n",
    "\n",
    "sample_text = \"\"\"We use the Pk metric as defined in Beeferman\n",
    "et al. (1999) to evaluate the performance of our\n",
    "model. Pk is the probability that when passing a\n",
    "sliding window of size k over sentences, the sentences at the boundaries of the window will be incorrectly classified as belonging to the same segment (or vice versa). To match the setup of Chen\n",
    "et al. (2009), we also provide the Pk metric for a\n",
    "sliding window over words when evaluating on the\n",
    "datasets from their paper\"\"\"\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "sample_sents = sent_detector.tokenize(sample_text)\n",
    "sample_sents = [sample_sents]\n",
    "sample_lengths = [len(s) for s in sample_sents]\n",
    "sample_lengths = torch.LongTensor(sample_lengths)\n",
    "sample_embs = batch_calc_docs_embs(sample_sents)\n",
    "sample_targets = torch.zeros(1, len(sample_sents[0]))\n",
    "sample_targets[:, sample_targets.shape[1]//2] = 1 # split into two segments in the middle\n",
    "\n",
    "# create dummy batch of copies\n",
    "batch_size = 2\n",
    "sample_embs = sample_embs.expand(batch_size, -1, -1)\n",
    "sample_targets = sample_targets.expand(batch_size, -1)\n",
    "sample_lengths = sample_lengths.expand(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brazen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\brazen\\Miniconda3\\envs\\default\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\brazen\\Miniconda3\\envs\\default\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brazen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brazen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from train_fit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.CRF import BiLSTM\n",
    "\n",
    "model = BiLSTM(2, 312, 256, 2, loss_fn='BinaryCrossEntropy')\n",
    "loss = model.loss(sample_embs, sample_lengths, sample_targets)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
